<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Markov Chain Monte Carlo for Hierarchical One Dimensional...</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for MCMCirtHier1d {MCMCpack}"><tr><td>MCMCirtHier1d {MCMCpack}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Markov Chain Monte Carlo for Hierarchical One Dimensional Item Response
Theory Model, Covariates Predicting Latent Ideal Point (Ability)</h2>

<h3>Description</h3>

<p>This function generates a sample from the posterior distribution of a one
dimensional item response theory (IRT) model, with multivariate Normal
priors on the item parameters, and a Normal-Inverse Gamma hierarchical prior
on subject ideal points (abilities).  The user supplies item-response data,
subject covariates, and priors. Note that this identification strategy
obviates the constraints used on theta in <code><a href="MCMCirt1d.html">MCMCirt1d</a></code>.
A sample from the posterior distribution is returned as an mcmc object,
which can be subsequently analyzed with functions provided in the coda
package.
</p>


<h3>Usage</h3>

<pre>
MCMCirtHier1d(datamatrix, Xjdata, burnin = 1000, mcmc = 20000,
  thin = 1, verbose = 0, seed = NA, theta.start = NA,
  a.start = NA, b.start = NA, beta.start = NA, b0 = 0, B0 = 0.01,
  c0 = 0.001, d0 = 0.001, ab0 = 0, AB0 = 0.25,
  store.item = FALSE, store.ability = TRUE,
  drop.constant.items = TRUE, marginal.likelihood = c("none",
  "Chib95"), px = TRUE, px_a0 = 10, px_b0 = 10, ...)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>datamatrix</code></td>
<td>
<p>The matrix of data.  Must be 0, 1, or missing values.  The
rows of <code>datamatrix</code> correspond to subjects and the columns correspond
to items.</p>
</td></tr>
<tr valign="top"><td><code>Xjdata</code></td>
<td>
<p>A <code>data.frame</code> containing second-level predictor
covariates for ideal points <i>&theta;</i>. Predictors are modeled as a
linear regression on the mean vector of <i>&theta;</i>; the posterior
sample contains regression coefficients <i>&beta;</i> and common
variance <i>&sigma;^2</i>. See Rivers (2003) for a thorough
discussion of identification of IRT models.</p>
</td></tr>
<tr valign="top"><td><code>burnin</code></td>
<td>
<p>The number of burn-in iterations for the sampler.</p>
</td></tr>
<tr valign="top"><td><code>mcmc</code></td>
<td>
<p>The number of Gibbs iterations for the sampler.</p>
</td></tr>
<tr valign="top"><td><code>thin</code></td>
<td>
<p>The thinning interval used in the simulation.  The number of
Gibbs iterations must be divisible by this value.</p>
</td></tr>
<tr valign="top"><td><code>verbose</code></td>
<td>
<p>A switch which determines whether or not the progress of the
sampler is printed to the screen. If <code>verbose</code> is greater than 0 then
every <code>verbose</code>th iteration will be printed to the screen.</p>
</td></tr>
<tr valign="top"><td><code>seed</code></td>
<td>
<p>The seed for the random number generator.  If NA, the Mersenne
Twister generator is used with default seed 12345; if an integer is passed
it is used to seed the Mersenne twister.  The user can also pass a list of
length two to use the L'Ecuyer random number generator, which is suitable
for parallel computation.  The first element of the list is the L'Ecuyer
seed, which is a vector of length six or NA (if NA a default seed of
<code>rep(12345,6)</code> is used).  The second element of list is a positive
substream number. See the MCMCpack specification for more details.</p>
</td></tr>
<tr valign="top"><td><code>theta.start</code></td>
<td>
<p>The starting values for the subject abilities (ideal
points). This can either be a scalar or a column vector with dimension equal
to the number of voters.  If this takes a scalar value, then that value will
serve as the starting value for all of the thetas.  The default value of NA
will choose the starting values based on an eigenvalue-eigenvector
decomposition of the agreement score matrix formed from the
<code>datamatrix</code>.</p>
</td></tr>
<tr valign="top"><td><code>a.start</code></td>
<td>
<p>The starting values for the <i>a</i> difficulty parameters.
This can either be a scalar or a column vector with dimension equal to the
number of items.  If this takes a scalar value, then that value will serve
as the starting value for all <i>a</i>.  The default value of NA will set
the starting values based on a series of probit regressions that condition
on the starting values of theta.</p>
</td></tr>
<tr valign="top"><td><code>b.start</code></td>
<td>
<p>The starting values for the <i>b</i> discrimination
parameters. This can either be a scalar or a column vector with dimension
equal to the number of items.  If this takes a scalar value, then that value
will serve as the starting value for all <i>b</i>.  The default value of
NA will set the starting values based on a series of probit regressions that
condition on the starting values of theta.</p>
</td></tr>
<tr valign="top"><td><code>beta.start</code></td>
<td>
<p>The starting values for the <i>&beta;</i> regression
coefficients that predict the means of ideal points <i>&theta;</i>.
This can either be a scalar or a column vector with length equal to the
number of covariates. If this takes a scalar value, then that value will
serve as the starting value for all of the betas.  The default value of NA
will set the starting values based on a linear regression of the covariates
on (either provided or generated) <code>theta.start</code>.</p>
</td></tr>
<tr valign="top"><td><code>b0</code></td>
<td>
<p>The prior mean of <i>&beta;</i>. Can be either a scalar or a
vector of length equal to the number of subject covariates. If a scalar all
means with be set to the passed value.</p>
</td></tr>
<tr valign="top"><td><code>B0</code></td>
<td>
<p>The prior precision of <i>&beta;</i>.  This can either be a
scalar or a square matrix with dimensions equal to the number of betas.  If
this takes a scalar value, then that value times an identity matrix serves
as the prior precision of beta. A default proper but diffuse value of .01
ensures finite marginal likelihood for model comparison.  A value of 0 is
equivalent to an improper uniform prior for beta.</p>
</td></tr>
<tr valign="top"><td><code>c0</code></td>
<td>
<p><i>c_0/2</i> is the shape parameter for the inverse Gamma
prior on <i>&sigma;^2</i> (the variance of <i>&theta;</i>). The
amount of information in the inverse Gamma prior is something
like that from <i>c_0</i> pseudo-observations.</p>
</td></tr>
<tr valign="top"><td><code>d0</code></td>
<td>
<p><i>d_0/2</i> is the scale parameter for the inverse Gamma
prior on <i>&sigma;^2</i> (the variance of <i>&theta;</i>). In
constructing the inverse Gamma prior, <i>d_0</i> acts like the sum of
squared errors from the <i>c_0</i> pseudo-observations.</p>
</td></tr>
<tr valign="top"><td><code>ab0</code></td>
<td>
<p>The prior mean of <code>(a, b)</code>. Can be either a scalar or a
2-vector. If a scalar both means will be set to the passed value. The prior
mean is assumed to be the same across all items.</p>
</td></tr>
<tr valign="top"><td><code>AB0</code></td>
<td>
<p>The prior precision of <code>(a, b)</code>.This can either be ascalar
or a 2 by 2 matrix. If this takes a scalar value, then that value times an
identity matrix serves as the prior precision. The prior precision is
assumed to be the same across all items.</p>
</td></tr>
<tr valign="top"><td><code>store.item</code></td>
<td>
<p>A switch that determines whether or not to store the item
parameters for posterior analysis.  <em>NOTE: In situations with many
items storing the item parameters takes an enormous amount of memory, so
<code>store.item</code> should only be <code>TRUE</code> if the chain is thinned
heavily, or for applications with a small number of items</em>.  By default, the
item parameters are not stored.</p>
</td></tr>
<tr valign="top"><td><code>store.ability</code></td>
<td>
<p>A switch that determines whether or not to store the
ability parameters for posterior analysis.  <em>NOTE: In situations with
many individuals storing the ability parameters takes an enormous amount of
memory, so <code>store.ability</code> should only be <code>TRUE</code> if the chain is
thinned heavily, or for applications with a small number of individuals</em>.
By default, ability parameters are stored.</p>
</td></tr>
<tr valign="top"><td><code>drop.constant.items</code></td>
<td>
<p>A switch that determines whether or not items
that have no variation should be deleted before fitting the model. Default =
TRUE.</p>
</td></tr>
<tr valign="top"><td><code>marginal.likelihood</code></td>
<td>
<p>Should the marginal likelihood of the
second-level model on ideal points be calculated using the method of Chib
(1995)? It is stored as an attribute of the posterior <code>mcmc</code> object and
suitable for comparison using <code><a href="BayesFactor.html">BayesFactor</a></code>.</p>
</td></tr>
<tr valign="top"><td><code>px</code></td>
<td>
<p>Use Parameter Expansion to reduce autocorrelation in the chain?
PX introduces an unidentified parameter <i>alpha</i> for the residual
variance in the latent data (Liu and Wu 1999). Default = TRUE</p>
</td></tr>
<tr valign="top"><td><code>px_a0</code></td>
<td>
<p>Prior shape parameter for the inverse-gamma distribution on
<i>alpha</i>, the residual variance of the latent data. Default=10.</p>
</td></tr>
<tr valign="top"><td><code>px_b0</code></td>
<td>
<p>Prior scale parameter for the inverse-gamma distribution on
<i>alpha</i>, the residual variance of the latent data. Default = 10</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>further arguments to be passed</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If you are interested in fitting K-dimensional item response theory models,
or would rather identify the model by placing constraints on the item
parameters, please see <code><a href="MCMCirtKd.html">MCMCirtKd</a></code>.
</p>
<p><code>MCMCirtHier1d</code> simulates from the posterior distribution using
standard Gibbs sampling using data augmentation (a Normal draw for the
subject abilities, a multivariate Normal draw for (second-level) subject
ability predictors, an Inverse-Gamma draw for the (second-level) variance of
subject abilities, a multivariate Normal draw for the item parameters, and a
truncated Normal draw for the latent utilities). The simulation proper is
done in compiled C++ code to maximize efficiency.  Please consult the coda
documentation for a comprehensive list of functions that can be used to
analyze the posterior sample.
</p>
<p>The model takes the following form.  We assume that each subject has an
subject ability (ideal point) denoted <i>&theta;_j</i> and that each
item has a difficulty parameter <i>a_i</i> and discrimination parameter
<i>b_i</i>.  The observed choice by subject <i>j</i> on item
<i>i</i> is the observed data matrix which is <i>(I \times J)</i>.
We assume that the choice is dictated by an unobserved utility:
</p>
<p style="text-align: center;"><i>z_{i,j} = -&alpha;_i + &beta;_i &theta;_j + \varepsilon_{i,j}</i></p>

<p>Where the errors are assumed to be distributed standard Normal.
This constitutes the measurement or level-1 model. The subject abilities
(ideal points) are modeled by a second level Normal linear predictor for
subject covariates <code>Xjdata</code>, with common variance
<i>&sigma;^2</i>. The parameters of interest are the subject
abilities (ideal points), item parameters, and second-level coefficients.
</p>
<p>We assume the following priors.  For the subject abilities (ideal points):
</p>
<p style="text-align: center;"><i>&theta;_j \sim \mathcal{N}(&mu;_{&theta;} ,T_{0}^{-1})</i></p>

<p>For the item parameters, the prior is:
</p>
<p style="text-align: center;"><i>&le;ft[a_i, b_i \right]' \sim \mathcal{N}_2 (ab_{0},AB_{0}^{-1})</i></p>

<p>The model is identified by the proper priors on the item parameters and
constraints placed on the ability parameters.
</p>
<p>As is the case with all measurement models, make sure that you have plenty
of free memory, especially when storing the item parameters.
</p>


<h3>Value</h3>

<p>An <code>mcmc</code> object that contains the sample from the posterior
distribution. This object can be summarized by functions provided by the
coda package. If <code>marginal.likelihood = "Chib95"</code> the object will have
attribute <code>logmarglike</code>.
</p>


<h3>Author(s)</h3>

<p>Michael Malecki, <a href="mailto:mike@crunch.io">mike@crunch.io</a>,
<a href="https://github.com/malecki">https://github.com/malecki</a>.
</p>


<h3>References</h3>

<p>James H. Albert. 1992. &ldquo;Bayesian Estimation of Normal Ogive
Item Response Curves Using Gibbs Sampling.&quot; <em>Journal of Educational
Statistics</em>.  17: 251&ndash;269.
</p>
<p>Joshua Clinton, Simon Jackman, and Douglas Rivers. 2004. &ldquo;The Statistical
Analysis of Roll Call Data.&quot;  <em>American Political Science Review</em> 98:
355&ndash;370.
</p>
<p>Valen E. Johnson and James H. Albert. 1999. &ldquo;Ordinal Data Modeling.&quot;
Springer: New York.
</p>
<p>Liu, Jun S. and Ying Nian Wu. 1999. &ldquo;Parameter Expansion for Data
Augmentation.&rdquo; <em>Journal of the American Statistical Association</em> 94:
1264&ndash;1274.
</p>
<p>Andrew D. Martin, Kevin M. Quinn, and Jong Hee Park. 2011.  &ldquo;MCMCpack:
Markov Chain Monte Carlo in R.&rdquo;, <em>Journal of Statistical Software</em>.
42(9): 1-21.  <a href="http://www.jstatsoft.org/v42/i09/">http://www.jstatsoft.org/v42/i09/</a>.
</p>
<p>Daniel Pemstein, Kevin M. Quinn, and Andrew D. Martin.  2007.  <em>Scythe
Statistical Library 1.0.</em> <a href="http://scythe.lsa.umich.edu">http://scythe.lsa.umich.edu</a>.
</p>
<p>Martyn Plummer, Nicky Best, Kate Cowles, and Karen Vines. 2006.  &ldquo;Output
Analysis and Diagnostics for MCMC (CODA)&rdquo;, <em>R News</em>. 6(1): 7-11.
<a href="https://CRAN.R-project.org/doc/Rnews/Rnews_2006-1.pdf">https://CRAN.R-project.org/doc/Rnews/Rnews_2006-1.pdf</a>.
</p>
<p>Douglas Rivers.  2004.  &ldquo;Identification of Multidimensional Item-Response
Models.&quot;  Stanford University, typescript.
</p>


<h3>See Also</h3>

<p><code><a href="../../coda/html/plot.mcmc.html">plot.mcmc</a></code>,<code><a href="../../coda/html/summary.mcmc.html">summary.mcmc</a></code>,
<code><a href="MCMCirtKd.html">MCMCirtKd</a></code>
</p>


<h3>Examples</h3>

<pre>

   ## Not run: 
data(SupremeCourt)

Xjdata &lt;- data.frame(presparty= c(1,1,0,1,1,1,1,0,0),
                     sex= c(0,0,1,0,0,0,0,1,0))

## Parameter Expansion reduces autocorrelation.
  posterior1 &lt;- MCMCirtHier1d(t(SupremeCourt),
                   burnin=50000, mcmc=10000, thin=20,
                   verbose=10000,
                   Xjdata=Xjdata,
                   marginal.likelihood="Chib95",
		   px=TRUE)

## But, you can always turn it off.
  posterior2 &lt;- MCMCirtHier1d(t(SupremeCourt),
                   burnin=50000, mcmc=10000, thin=20,
                   verbose=10000,
                   Xjdata=Xjdata,
                   #marginal.likelihood="Chib95",
		   px=FALSE)
## Note that the hierarchical model has greater autocorrelation than
## the naive IRT model.
  posterior0 &lt;- MCMCirt1d(t(SupremeCourt),
                        theta.constraints=list(Scalia="+", Ginsburg="-"),
                        B0.alpha=.2, B0.beta=.2,
                        burnin=50000, mcmc=100000, thin=100, verbose=10000,
                        store.item=FALSE)

## Randomly 10% Missing -- this affects the expansion parameter, increasing
## the variance of the (unidentified) latent parameter alpha.

   scMiss &lt;- SupremeCourt
   scMiss[matrix(as.logical(rbinom(nrow(SupremeCourt)*ncol(SupremeCourt), 1, .1)),
      dim(SupremeCourt))] &lt;- NA

   posterior1.miss &lt;- MCMCirtHier1d(t(scMiss),
                   burnin=80000, mcmc=10000, thin=20,
                   verbose=10000,
                   Xjdata=Xjdata,
                   marginal.likelihood="Chib95",
		   px=TRUE)

   
## End(Not run)

</pre>

<hr /><div style="text-align: center;">[Package <em>MCMCpack</em> version 1.4-6 <a href="00Index.html">Index</a>]</div>
</body></html>
